# Chapter3 운영체제

1. [운영체제와 컴퓨터](#31-운영체제와-컴퓨터)
2. [메모리](#32-메모리)
3. [프로세스와 스레드](#33-프로세스와-스레드)
4. [CPU 스케줄링 알고리즘](#34-cpu-스케줄링-알고리즘)

### 운영체제란?

사용자가 컴퓨터를 쉽게 다루게 해주는 인터페이스

- **펌웨어** : 운영체제와 유사하지만 소프트웨어를 추가로 설치할 수 없는 것

# 3.1 운영체제와 컴퓨터

## 3.1.1 운영체제의 역할과 구조

### **운영체제 역할 4가지**

1. **CPU 스케줄링과 프로세스 관리**
   CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환을 관리
2. **메모리 관리**
   한정된 메모리를 어떤 프로세스에 얼마큼 할당해야하는지 관리
3. **디스크 파일 관리**
   디스크 파일을 어떠한 방법으로 보관할지 관리
4. **I/O 디바이스 관리**
   마우스, 키보드와 컴퓨터 간에 데이터를 주고받는 것을 관리

### **운영체제 구조**

유저프로그램
|
인터페이스(GUI, CUI)
|
시스템콜
|
커널
|
하드웨어

**CUI** : 그래픽이 아닌 명령어로 처리하는 인터페이스

**드라이버** : 하드웨어를 제어하기 위한 소프트웨어

**GUI** : 아이콘을 마우스로 클릭하는 단순한 동작으로 컴퓨터와 상호 작용할 수 있도록 함

**시스템콜**

운영체제가 커널에 접근하기 위한 인터페이스

유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출할 때 씀

1. 유저 모드에서 파일 읽기 X
2. 커널 모드로 들어가 파일을 읽고 다시 유저모드로 돌아가야함
3. 그리고 그 뒤에 있는 유저 프로그램 수행

**⇒ 효과 : 컴퓨터 자원에 대한 직접 접근을 차단! 프로그램을 다른 프로그램으로부터 보호할 수 있음**

**modebit**

시스템콜이 작동될 때 modebit을 참고해서 유저모드와 커널모드를 구분

modebit ⇒ 1, 0 의 값을 가지는 플래그변수

**0 ⇒ 커널모드**

**1 ⇒ 유저모드**

**유저 모드** : 유저가 접근할 수 있는 영역을 제한적으로 두며 컴퓨터 자원에 함부로 침범하지 못하는 모드

**커널 모드** : 모든 컴퓨터 자원에 접근할 수 있는 모드

**커널** : 운영체제의 핵심 부분 / 시스템콜 인터페이스를 제공하며 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 운영체제의 중추적인 역할

## 3.1.2 컴퓨터의 요소

CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져 있음

### CPU

**Central Processing Unit**

산술논리연산장치, 제어장치, 레지스터로 구성되어 있는 컴퓨터 장치

운영체제 커널이 프로그램을 메모리에 올려 프로세스를 만들면 CPU 가 프로세스를 처리

**제어장치 (CU/ Control Unit)**

프로세스 조작을 지시하는 CPU의 한 부품

입출력장치 간 통신을 제어하고 명령어들을 읽고 해석하며 데이터 처리를 위한 **순서를 결정**

**레지스터**

CPU안에 있는 매우 빠른 임시기억장치

CPU와 **직접 연결**되어 있음

연산 속도가 메모리보다 수십 배에서 수백 배까지 빠름

CPU는 자체적으로 데이터를 저장 X, 그래서 **레지스터를 거쳐 데이터 전달**

**산술논리연산장치 (ALU/ Arichmetic Logic Unit)**

ALU → 덧셈, 뺄셈 같은 두 숫자의 산술 연산과 배타적 논리합, 논리곱 같은 논리 연산을 계산하는 디지털 회로

### CPU의 연산처리

제어장치, 레지스터, 산술논리연산장치를 통해 연산하는 예

1. 제어장치가 메모리에 계산할 값을 로드, 레지스터에도 로드
2. 제어장치가 레지스터에 있는 값을 계산하라고 산술논리연상장치에 명령
3. 제어장치가 계산된 값을 다시 "레지스터에서 메모리로" 계산한 값을 저장

**하드웨어 인터럽트**

I/O 디바이스에서 발생하는 인터럽트

**소프트웨어 인터럽트**

트랩이라고도 함. 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발동

### DMA 컨트롤러

I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치

CPU에만 너무 많은 인터럽트 요청이 들어오기 때문에 CPU 부하를 막아주며 CPU의 일을 부담하는 보조일꾼

하나의 작업을 CPU와 DMA 컨트롤러가 동시에 하는 것을 방지함

### 메모리

전자회로에서 데이터나 상태, 명령어 등을 기록하는 장치

RAM - 메모리

**`CPU → 계산`**

**`메모리 → 기억`**

### 타이머

프로그램이 작동할 때 시간 제한을 걺

### 디바이스 컨트롤러

컴퓨터와 연결되어 있는 IO 디바이스들의 작은 CPU를 말하고 옆에 붙어 있는 로컬 버퍼는 각 디바이스에서 데이터를 임시로 저장하기 위한 작은 메모리를 뜻함

# 3.2 메모리

## 3.2.1 메모리 계층

메모리 계층 : 레지스터, 캐시, 메모리, 저장장치로 구성

- 레지스터 : CPU안에 있는 작은 메모리 / 휘발성, 속도 GOOD, 기억 용량 적음
- 캐시 : L1, L2 캐시 / 휘발성, 속도 GOOD, 기억용량 적음, L3 캐시도 있음
- 주기억장치 : RAM / 휘발성, 속도 보통, 기억용량 보통
- 보조 기억장치 : HDD , SSD / 비휘발성, 속도 낮음, 기억 용량 많음
  ⇒ 계층위로 올라갈수록 가격 올라감, 용량 작아짐, 속도 빠름

**`램`** : 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장 / 이를 필요 시마다 CPU에 빠르게 전달하는 역할

**`캐시`** : 데이터를 미리 복사해 놓는 임시 저장소 / 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리

캐시 메모리와 보조기억장치 사이에 있는 **주기억장치**를 **보조기억장치의 캐싱 계층**이라고 할 수 있음

**지역성**

1. **시간지역성**
2. **공간지역성**

**시간 지역성**

최근 사용한 데이터에 다시 접근하려는 특성

**공간지역성**

최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

### 캐시 히트

캐시에서 원하는 데이터를 찾았으면 캐시히트

CPU 내부 버스를 기반으로 작동하기 때문에 빠름

### 캐시 미스

해당 데이터가 캐시에 **없다면** 주메모리로 가서 데이터를 찾아오는 것

메모리에서 가져오는데, 시스템 버스를 기반으로 작동해서 느림

**캐시매핑**

캐시가 히트되기 위해 매핑하는 방법

CPU의 레지스터와 주 메모리간에 데이터를 주고받을 때를 기반으로 설명

**웹브라우저의 캐시**

1. **쿠키**

- 정의
  - 만료 기한이 **있는** 키-값 저장소
- 특징
  - same site 옵션을 strict로 설정하지 않았을 경우 다른 도메인에서 요청했을 때 자동 전송 -> CSRF 위험
  - 용량 약 4kb까지 데이터를 저장 가능
  - 만료기한 설정 가능
  - document.cookie로 쿠키를 볼 수 없게 httponly 옵션 걸기

2. **로컬 스토리지**

- 정의
  - 만료기한이 **없는** 키-값 저장소
- 특징
  - 5MB까지 저장 가능
  - 웹브라우저를 닫아도 유지됨
  - HTML5를 지원하지 않는 웹브라우저에서는 사용할 수 없음

3. **세션 스토리지**

- 정의
  - 만료기한이 **없는** 키-값 저장소
- 특징
  - 탭 단위로 세션 스토리지를 생성
  - 탭을 닫을 때 해당 데이터가 삭제됨
  - 5MB까지 저장 가능
  - HTML5를 지원하지 않는 웹브라우저에서는 사용할 수 없음
  - 클라이언트에서만 수정 가능

## 3.2.2 메모리 관리

### 가상메모리

- 메모리 관리 기법의 하나
- 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화 -> 사용자들에게 매우 큰 메모리로 보이게 만드는 것

**스와핑 (예시로 알아보자!)**

**상황** : 가상 메모리에는 존재하는데 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트가 발생

**해결** : 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것

⇒ 페이지 폴트가 일어나지 않은 것처럼 만듦

**페이지 폴트**

프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우에 발생

**페이지**

가상 메모리를 사용하는 최소 크기 단위

**프레임**

실제 메모리를 사용하는 최소 크기 단위

### 스레싱

- 메모리의 페이지 폴트율이 높은 것
- 컴퓨터의 심각한 성능 저하를 초래
- 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생

**스레싱 해결 방법**

1. 메모리를 늘리기
2. HDD를 SSD로 변경하기
3. 운영체제에서는 작업세트와 PFF 사용

**작업세트**

- 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것

**PFF**

- 페이지 폴트 빈도를 조절하는 방법
- 상한선에 도달하면 프레임을 늘리고
- 하한선에 도달하면 프레임을 줄임

### 메모리 할당

**연속할당**, **불연속 할당**

#### 1. **연속할당**

메모리에 **‘연속적으로’** 공간을 할당하는 것

- 고정분할방식 → 메모리를 미리 나누어 관리, 내부 단편화 발생 가능
- 가변분할방식 → 동적으로 메모리를 나눠 사용, 외부 단편화 발생 가능

> 내부 단편화 <br>
> 할당받은 메모리 블록 내부에 사용되지 않는 여유공간이 생기는 것
> 해결 방법 -> 블록 크기 조정..

> 외부 단편화 <br>
> 메모리 전체를 보면 빈 공간이 많지만 연속적으로 충분히 큰 빈 공간이 없어서 할당이 불가능한 상태
> ex) 프로세스 생성/종료로 메모리가 여기저기 조각난 상황에서
> 해결 방법 -> 압축, 페이징..

**가변 분할 방식 종류**
최초 적합 : 빈 공간 리스트를 처음부터 검색 → 첫 번째 맞는 홀 사용

최적 적합 : 모든 홀을 검색 → 요청 크기에 가장 근접한 홀 사용

최악 적합 : 모든 홀을 검색 → 요청 크기보다 가장 큰 홀 사용

#### 2. **불연속 할당**

EX) 페이징 기법, 세그멘테이션, 페이지드 세그멘테이션

메모리를 동일한 크기의 페이지 (보통 4KB)로 나누고 프로그램마다 페이지 테이블을 두어서 메모리에 프로그램을 할당함

### 페이지 교체 알고리즘

**스와핑**은 **페이지 교체 알고리즘을 기반**으로 일어난다!

**오프라인 알고리즘**

먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘

가장 좋지만 현실적으로 미래에 사용되는 프로세스를 우리는 알 수 X

=> 즉 사용할 수 없는 알고리즘
=> 하지만 가장 좋은 알고리즘이기 때문에 다른 알고리즘과의 성능 비교에 대한 상한 기준을 제공

**FIFO**

가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법을 의미

**LRU**

참조가 가장 오래된 페이지를 바꿈

LRU를 구현할때는 보통 해시테이블, 이중 연결 리스트를 이용

**NUR**

NOT USED RECENTLY

일명 CLOCK 알고리즘, 0과 1을 가진 비트를 두어 구현

**`1 → 최근 참조됨을 의미`**

**`0 → 참조되지 않음을 의미`**

시계방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고 해당 부분을 1로 바꾸는 알고리즘

**LFU**

LEAST FREQUENTLY USED 가장 참조 횟수가 적은 페이지를 교체

많이 사용되지 않은 것을 교체

# 3.3 프로세스와 스레드

- 프로세스 = 작업
- 스레드 = 프로세스 내 작업의 흐름

1. 프로그램이 메모리에 올라가면 ⇒ 프로세스 (인스턴스화)
2. 운영체제의 스케줄러에 따라 CPU가 프로세스 실행

## 3.3.1 프로세스와 컴파일 과정

프로세스 = 프로그램이 메모리에 올라가 인스턴스화 된 것

1. **전처리**

소스코드의 주석을 제거
헤더 파일 병합하여 메크로 치환

2. **컴파일러**

오류 처리, 코드 최적화 작업을 하며 어셈블리어로 변환

3. **어셈블러**

어셈블리어 → 기계가 이해 가능한 목적 코드로 변환

(리눅스는 .o 라는 확장자)

4. **링커**

프로그램 내에 있는 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합하여 실행 파일을 만듦

(확장자 - .exe, .out)

### 라이브러리 (c/c++ 등 기준)

1. **정적라이브러리**

- 프로그램 빌드 시 라이브러리가 제공하는 모든 코드를 실행 파일에 넣는 방식
- 장점 : 외부 의존도가 낮음
- 단점 : 메모리 효율성이 떨어짐

2. **동적라이브러리**

- 프로그램 실행 시 필요할 때만 DLL이라는 함수 정보를 통해 참조하여 라이브러리를 씀
- 장점 : 메모리 효율성에서의 장점
- 단점 : 외부 의존도가 높음

## 3.3.2 프로세스의 상태

### 생성 상태

- OS가 스케줄링을 위해 PCB만들고 메모리에 올림
- 프로세스가 생성된 상태
- fork() 또는 exec() 함수를 통해 생성

**fork()** - 부모 프로세스 복제

- 부모 프로세스의 주소 공간을 그대로 복사
- 새로운 자식 프로세스를 생성
- 상속되지 않는 것 : 부모 프로세스의 비동기 작업등을 상속 x

**exec()** - 완전 새로운 프로그램으로 교체

exec()를 호출한 프로세스의 PID가 그대로 새로운 프로세스에 적용
exec()를 호출한 프로세스는 새로운 프로세스에 의해 덮어 쓰여짐

### **대기 상태**

메모리 공간이 충분하면 메모리를 할당받고

아니면 아닌 상태로 대기하고 있으며

cpu 스케줄러로부터 cpu 소유권이 넘어오기를 기다리는 상태

### 대기중단상태

메모리 부족으로 일시 중단된 상태

### 실행상태

cpu 소유권과 메모리를 할당받고 인스트럭션을 수행중인 상태

=> cpu burst가 일어났다

### 중단상태

어떤 이벤트 발생이후 기다리며 프로세스 차단된 상태

ex) i/o 디바이스에 의한 인터럽트로 발생

### 일시중단상태

대기중단과 유사

중단된 상태에서 프로세스가 실행되려고 했지만 메모리 부족으로 일시 중단

### 종료상태

메모리와 cpu 소유권을 모두 놓고 가는 상태

## 3.3.3 프로세스의 메모리 구조

### 스택과 힙 (동적 영역)

**스택**

→ 지역변수, 매개변수, 실행되는 함수에 의해 늘거나 줄어드는 메모리 영역

→ 함수가 호출될 때마다 호출될 때의 환경 등 특정 정보가 스택에 계속 저장

**힙**

→ 동적으로 할당되는 변수들을 담음

→ malloc(), free() 함수를 통해 관리 가능

### 데이터 영역과 코드영역 (정적 영역)

**데이터 영역**

→ 1. BSS sagement, 2. Data segment, 3. code/text segment

1. **BSS Sagement**

전역변수, static, const로 선언되어 있고 0으로 초기화 또는 초기화가 어떤 값으로도 되지 않은 변수들이 할당되는 구역

2. **Data Sagement**

전역변수, static, const로 선언되어 있고 0이 아닌 값으로 초기화된 변수가 할당되는 구역

3. **code segment**

프로그램의 코드

## 3.3.4 PCB

### **Process control block**

- 운영체제에서 프로세스에 대한 메타데이터를 저장한 ‘데이터’
- 프로세스 제어 블록
- 프로세스가 생성되면 운영체제는 해당 PCB를 생성
- PCB는 커널 스택의 가장 앞부분에서 관리됨

### 컨텍스트 스위칭

- PCB를 기반으로 프로세스의 상태를 저장하고 로드시키는 과정
- 컴퓨터는 어떠한 시점에서 실행되고 있는 프로세스는 단 한 개
- 많은 프로세스가 동시에 구동되는 것처럼 보이는 것 = 다른 프로세스와의 컨텍스트 스위칭이 아주 빠르게 실행되어서

⇒ 근데 사실 현대는 멀티코어의 CPU를 가지기 때문에 틀린 설명
⇒ 근데 컨텍스트 스위칭을 설명할 때는 싱글코어를 기준으로 설명함

컨텍스트 스위칭이 일어날 때 **유휴시간** 이 발생한다

컨텍스트 스위칭이 일어날 때 **캐시미스(비용)**이 발생한다

## 3.3.5 멀티프로세싱

멀티프로세스를 동시에 두 가지 이상의 일을 수행할 수 있는 것

⇒ 병렬 처리!

### 웹 브라우저

멀티프로세스 구조를 가지고 있음

### IPC

프로세스끼리 데이터를 주고 받고 공유 데이터를 관리하는 메커니즘

클라이언트 ↔ 서버 IPC의 예

IPC의 종류 : 공유 메모리, 파일, 소켓, 익명파이프, 명명 파이프, 메시지 큐

**공유 메모리**

여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어 프로세스가 서로 통신할 수 있도록 공유 메모리를 생성해서 통신하는 것

**파일**

디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터

**소켓**

동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터를 의미함

EX) TCP, UDP

**익명 파이프**

프로세스 간에 FIFO 방식으로 읽히는 임시 공간이 파이프를 기반으로 데이터를 주고 받으면서 단방향 읽기 전용, 쓰기전용 파이프를 만들어서 작동하는 방식

**명명 파이프**

파이프 서버와 하나이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향 또는 양방향 파이프

**메시지 큐**

메시지를 큐 데이터 구조 형태로 관리하는 것

## 3.3.6 스레드와 멀티스레딩

### 스레드

프로세스의 실행가능한 가장 작은 단위

프로세스는 여러 스레드를 가질 수 있음

스레드는 코드 영역, 데이터 영역, 힙 영역 서로 공유함

### 멀티 스레딩

프로세스 내 작업을 여러 개의 스레드, 멀티스레드로 처리하는 기법

**장점** : 효율성이 높음, 동시성 처리에도 좋음

**단점** : 문제가 생기면 다른 스레드에도 영향을 미침

## 3.3.7 공유자원과 임계영역

### 공유자원

시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 잇는 모니터, 프린터, 메모리, 파일, 데이터 등의 자원이나 변수

**`경쟁상태란`**? 공유자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황

### 임계 영역

둘 이상의 프로세스, 스레드가 공유 자원에 접근할 때 순서 등의 이유로 결과가 달라지는 코드 영역

**해결 방법**

1. **뮤텍스**
2. **세마포어**
3. **모니터**

⇒ 1,2,3은 모두 상호 배제, 한정 대기, 융통성 을 만족시킴
⇒ 토대 매커니즘 : 잠금 LOCK

**`상호배제`** : 한프로세스가 임계 영역에 들어갔을 때 다른 프로세스는 들어갈 수 없다

**`한정 대기`** : 특정 프로세스가 영원히 임계 영역에 들어가지 못하면 안된다

**`융통성`** : 어떤 프로세스도 임계영역 사용안하면 임계 영역 외부의 어떠한 프로세스도 들어갈 수 있으며 이때 프로세스끼리 서로 방해하지 않는다

### 뮤텍스

- 프로세스나 스레드가 공유 자원을 LOCK을 통해 잠금 설정하고 사용한 후에는 UNLOCK을 통해 잠금 해제하는 객체

### 세마포어

- 일반화된 뮤텍스
  - 세마포어는 자원 개수를 1이 아닌 N개로 확장해서 관리 가능
  - 뮤텍스는 항상 하나만 허용하기에..
- 간단한 정수값과 두가지 함수 P함수 = wait(), V함수 = signal()로 공유 자원에 대한 접근을 처리함
  > 여러 프로세스/스레드가 공유 자원 접근을 통제하기 위해 사용되는 동기화 도구
- 1 → 사용 가능
- 0 → 이미 다른 프로세스가 사용 중
- 음수 → 대기 중 스레드 존재

> 왜 P / V 라고 부를까?
> 
> 네덜란드어 원래 명칭에서 유래:
> P: Proberen (시험/시도하다)
> V: Verhogen (증가시키다)
> P와 V함수는 쌍으로 사용!

| 연산           | 의미      | 역할                   |
| -------------- | --------- | ---------------------- |
| **P (wait)**   | 자원 요청 | 세마포어 값 감소, 대기 |
| **V (signal)** | 자원 반납 | 세마포어 값 증가, 깨움 |

### 모니터

- 둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유자원을 숨기고 해당 접근에 대해 인터페이스만 제공
  => 캡슐화 + 동기화 기능

## 3.3.8 교착 상태

두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태

### 교착상태의 원인

**상호 배제** : 한 프로세스가 자원 독점

**점유 대기** : 이미 점유한 자원을 다른 프로세스가 요청하는 상태

**비선점** : 다른 프로세스의 자원을 강제적으로 가져올 수 없음

**환형대기** : 서로가 서로의 자원을 요구하는 상태

### 해결방법

1. 애초에 조건이 성립되지 않도록 설계
2. 은행원 알고리즘 사용
3. 사이클이 있는지 찾아보고, 이에 관련된 프로세스를 한 개씩 지움
4. 그냥 사용자가 작업 종료

## 3.4 CPU 스케줄링 알고리즘

- CPU 스케줄러는 CPU 스케줄링 알고리즘에 따라 프로세스에서 해야 하는 일을 **스레드 단위**로 CPU에 할당
- CPU 스케줄링 알고리즘이 어떤 프로그램에 CPU 소유권을 줄 것인지 결정

### 3.4.1 비선점형 방식

- 프로세스가 스스로 CPU 소유권을 포기하는 방식
- 운영체제가 강제로 프로세스를 중지하지 않음
- 장점 : 컨텍스트 스위칭으로 인한 부하가 적음

#### FCFS (FIRST COME, FIRST SERVED)

- 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘
- 장점 : 간단
- 단점 : 준비 큐에서 오래 기다리는 현상이 발생한다는 단점

#### SJF (SHORTEST JOB FIRST)

- 실행시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘
- 장점 : 평균 대기 시간이 가장 짧음
- 단점1 : 긴 시간을 가진 프로세스가 실행되지 않는 현상이 발생 가능
- 단점2 : 실제로는 실행시간을 알 수 없음 -> 과거의 실행했던 시간을 토대로 추측해서 사용함 (과거 실행시간이 없을 떄 처리방법도 존재)

#### 우선순위 스케줄링

- 정해진 우선순위가 높은 프로세스를 먼저 실행
- 오래된 작업일수록 ‘우선순위를 높이는 방법’ (에이징 기법)

### 3.4.2 선점형 방식

현대 운영체제가 쓰는 방식

지금 사용하고 있는 프로세스를 알고리즘에 의해 **중단**시켜 버리고 강제로 다른 프로세스에 CPU 소유권을 할당하는 방식

#### 라운드 로빈

현대 컴퓨터가 쓰는 **선점형** 알고리즘 스케줄링 방법

1. 각 프로세스는 동일한 할당 시간 부여
2. 정해진 시간 동안 실행
3. 그 시간 안에 끝나지 않으면 다시 준비 큐의 뒤로 이동

#### SRTF (SHORTEST REMAINING TIME FIRST)

남은 시간이 가장 짧은 프로세스를 우선 실행하는 선점형 스케줄링

1. 새 프로세스가 도착할때마다
   -> 현재 실행중인 프로세스와 남은 실행시간 비교
2. 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지하고 해당 프로세스를 수행

#### 다단계 큐

우선순위에 따른 준비 큐를 여러개 사용해서 각각 다른 스케줄링 정책 적용

큐마다 라운드 로빈이나 FCFS 등 다른 스케줄링 알고리즘을 적용한 것

특징 : 큐간의 프로세스 이동이 안됨

⇒ 스케줄링 부담이 적음
=> BUT 유연성이 떨어짐
